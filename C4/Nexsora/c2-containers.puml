@startuml C2-Containers-Nexora
!include https://raw.githubusercontent.com/plantuml-stdlib/C4-PlantUML/master/C4_Container.puml

title Diagrama de Containers - Plataforma SaaS Nexora com Dados Vetorizados para RAG

Person(usuario, "Usuário", "Técnicos de manutenção, gestores de ativos e operadores")
Person(admin, "Admin/Configurador", "Configura triggers de análise preditiva")
Person(gestor_ativos, "Gestor de Ativos", "Cadastra equipamentos, sensores e manuais")

System_Boundary(nexora_boundary, "Plataforma SaaS Nexora") {
    Container(web_app, "Aplicação Web", "React + TypeScript", "Interface de usuário para monitoramento, dashboards e configuração de triggers")
    Container(api_gateway, "API Gateway", "Kong/Nginx", "Ponto de entrada unificado, autenticação e roteamento de requisições")
    
    ' === GESTÃO DE DADOS MESTRE ===
    Container(equipment_service, "Equipment Management Service", "Python + FastAPI", "CRUD de equipamentos, hierarquia e classificação")
    Container(sensor_service, "Sensor Management Service", "Python + FastAPI", "CRUD de sensores, tipos e especificações")
    Container(manual_service, "Manual & Documentation Service", "Python + FastAPI", "CRUD de manuais, procedimentos e FMEA")
    Container(maintenance_history_service, "Maintenance History Service", "Python + FastAPI", "Histórico completo de manutenções e falhas")
    
    ' === PROCESSAMENTO PARA RAG ===
    Container(document_processor, "Document Processor", "Python + LangChain", "Processa documentos e gera embeddings para RAG")
    Container(vector_indexer, "Vector Indexer", "Python + LangChain", "Indexa e gerencia embeddings no banco vetorizado")
    
    ' === PIPELINE OPERACIONAL ===
    Container(data_ingestion, "Entrada no Sistema", "Python/FastAPI", "Recebe e processa dados de sensores IoT")
    Container(observer, "Observador", "Python", "Observa mudanças e emite eventos para coordenação")
    Container(event_queue, "Fila de Eventos", "RabbitMQ", "Hub central de coordenação entre agentes AI")
    
    Container(trigger_manager, "Trigger Manager", "Python + Celery", "Gerencia triggers configuráveis para análise preditiva")
    
    ' === AGENTES AI ===
    Container(anomaly_agent, "Agent Detecção Anomalias", "Python + LangChain", "Detecta padrões anômalos em dados de sensores")
    Container(predictive_agent, "Agent Análise Preditiva", "Python + LangChain", "Prediz falhas (acionado sob demanda via triggers)")
    Container(maintenance_agent, "Agent Necessidades Manutenção", "Python + LangChain", "Identifica necessidades de manutenção")
    Container(workorder_agent, "Agent Emissão OS", "Python + LangChain", "Gera ordens de serviço priorizadas")
    
    ' === RAG E TOOLS ===
    Container(rag_service, "RAG Service", "Python + LangChain", "Retrieval-Augmented Generation usando dados vetorizados")
    Container(internal_tools, "Tools Internas", "Python", "Ferramentas que não acessam sistemas externos")
    Container(docker_mcp_gateway, "Docker MCP Gateway", "Docker MCP Server", "Controla ferramentas que acessam sistemas externos")
    
    Container(monitoring, "Observabilidade", "Prometheus/Grafana/Jaeger", "Coleta de métricas, logs e traces distribuídos")
}

' === BANCOS DE DADOS SEPARADOS POR TIPO ===
ContainerDb(postgres, "PostgreSQL", "PostgreSQL 15", "Dados estruturados: equipamentos, sensores, configurações, histórico de manutenções")
ContainerDb(timeseries_db, "InfluxDB/TimescaleDB", "Time Series Database", "Dados temporais: histórico de sensores IoT")
ContainerDb(vector_db, "Pinecone Vector DB", "Pinecone Cloud", "Dados vetorizados: embeddings de manuais, FMEA, procedimentos, casos históricos")
ContainerDb(file_storage, "MinIO/S3", "Object Storage", "Arquivos originais: PDFs, imagens, documentos técnicos")
ContainerDb(cache, "Redis", "Redis Cluster", "Cache de sessões e consultas frequentes")

System_Ext(sensores, "Sensores IoT", "Dispositivos de monitoramento")
System_Ext(erp, "Sistemas ERP", "SAP, Oracle, outros ERPs")
System_Ext(notificacoes, "Serviços de Notificação", "WhatsApp, Email, SMS")

' === FLUXOS DE GESTÃO DE DADOS MESTRE ===
Rel(gestor_ativos, web_app, "Cadastra dados mestre", "HTTPS")
Rel(web_app, api_gateway, "CRUD operations", "HTTPS")
Rel(api_gateway, equipment_service, "Equipment CRUD", "HTTP")
Rel(api_gateway, sensor_service, "Sensor CRUD", "HTTP")
Rel(api_gateway, manual_service, "Manual CRUD", "HTTP")
Rel(api_gateway, maintenance_history_service, "History CRUD", "HTTP")

' === PERSISTÊNCIA DE DADOS ESTRUTURADOS ===
Rel(equipment_service, postgres, "Equipment data", "SQL")
Rel(sensor_service, postgres, "Sensor data", "SQL")
Rel(manual_service, postgres, "Manual metadata", "SQL")
Rel(maintenance_history_service, postgres, "History data", "SQL")

' === ARMAZENAMENTO DE ARQUIVOS ===
Rel(manual_service, file_storage, "Store PDFs/Documents", "S3 API")

' === PROCESSAMENTO PARA VETORIZAÇÃO ===
Rel(manual_service, document_processor, "Process new documents", "HTTP")
Rel(maintenance_history_service, document_processor, "Process maintenance cases", "HTTP")
Rel(document_processor, file_storage, "Read original files", "S3 API")
Rel(document_processor, postgres, "Read metadata", "SQL")
Rel(document_processor, vector_indexer, "Send processed content", "HTTP")
Rel(vector_indexer, vector_db, "Store embeddings", "Pinecone API")

' === FLUXO OPERACIONAL ===
Rel(sensores, data_ingestion, "Envia telemetria", "MQTT/HTTP")
Rel(data_ingestion, sensor_service, "Valida sensor registration", "HTTP")
Rel(data_ingestion, timeseries_db, "Store sensor data", "InfluxDB Protocol")
Rel(data_ingestion, observer, "Dados processados", "HTTP")
Rel(observer, event_queue, "Emite eventos", "AMQP")

' === TRIGGER LOGIC ===
Rel(admin, web_app, "Configura triggers", "HTTPS")
Rel(api_gateway, trigger_manager, "Trigger config", "HTTP")
Rel(trigger_manager, postgres, "Store trigger config", "SQL")
Rel(event_queue, trigger_manager, "Monitor data", "AMQP")
Rel(trigger_manager, timeseries_db, "Evaluate thresholds", "InfluxQL")
Rel(trigger_manager, event_queue, "Trigger predictive analysis", "AMQP")

' === PIPELINE DE AGENTES COM DADOS CONTEXTUALIZADOS ===
Rel(event_queue, anomaly_agent, "Sensor data events", "AMQP")
Rel(anomaly_agent, timeseries_db, "Query historical data", "InfluxQL")
Rel(anomaly_agent, equipment_service, "Equipment context", "HTTP")
Rel(anomaly_agent, sensor_service, "Sensor specs", "HTTP")

Rel(event_queue, predictive_agent, "Trigger events", "AMQP")
Rel(predictive_agent, timeseries_db, "Time series analysis", "InfluxQL")
Rel(predictive_agent, maintenance_history_service, "Historical patterns", "HTTP")
Rel(predictive_agent, equipment_service, "Equipment specs", "HTTP")

Rel(event_queue, maintenance_agent, "Prediction events", "AMQP")
Rel(maintenance_agent, rag_service, "Query knowledge base", "HTTP")
Rel(maintenance_agent, equipment_service, "Equipment details", "HTTP")
Rel(maintenance_agent, maintenance_history_service, "Similar cases", "HTTP")

Rel(event_queue, workorder_agent, "Maintenance events", "AMQP")
Rel(workorder_agent, equipment_service, "Equipment hierarchy", "HTTP")
Rel(workorder_agent, maintenance_history_service, "Log maintenance", "HTTP")

' === RAG SERVICE COM DADOS VETORIZADOS ===
Rel(rag_service, vector_db, "Vector similarity search", "Pinecone API")
Rel(rag_service, postgres, "Metadata enrichment", "SQL")
Rel(rag_service, cache, "Cache frequent queries", "Redis")

' === AGENTES AI ACESSANDO RAG ===
Rel(anomaly_agent, rag_service, "Query sensor knowledge", "HTTP")
Rel(predictive_agent, rag_service, "Query maintenance patterns", "HTTP")

' === TOOLS E INTEGRAÇÕES ===
Rel(workorder_agent, internal_tools, "Internal tools", "HTTP")
Rel(workorder_agent, docker_mcp_gateway, "External tools", "MCP Protocol")
Rel(docker_mcp_gateway, erp, "ERP integration", "REST/SOAP")
Rel(docker_mcp_gateway, notificacoes, "Notifications", "REST API")

' === INTERFACE USUÁRIO ===
Rel(usuario, web_app, "Access dashboards", "HTTPS")
Rel(api_gateway, postgres, "Query operational data", "SQL")
Rel(api_gateway, timeseries_db, "Query metrics", "InfluxQL")
Rel(api_gateway, cache, "Cache responses", "Redis")

' === MONITORAMENTO ===
Rel(monitoring, event_queue, "Monitor events", "HTTP")
Rel(monitoring, timeseries_db, "Collect metrics", "InfluxQL")
Rel(monitoring, vector_db, "Monitor vector operations", "HTTP")

SHOW_LEGEND()
@enduml