# ADR-003: Arquitetura RAG-First com Deduplica√ß√£o Inteligente

**Status**: Aceito  
**Data**: 2025-09-08  
**Autor**: Equipe de Arquitetura  

## Contexto

Com a implementa√ß√£o completa da gest√£o de dados mestre (ADR-002), identificamos a necessidade de otimizar o acesso dos agentes AI √†s informa√ß√µes contextualizadas. O desafio principal era eliminar a depend√™ncia direta dos agentes aos servi√ßos CRUD, centralizando todo o conhecimento em uma base vetorizada para melhor performance e consist√™ncia.

### Problemas Identificados:

1. **Acesso Fragmentado**: Agentes consultavam m√∫ltiplos servi√ßos CRUD para obter contexto
2. **Duplica√ß√£o de Processamento**: Manuais e especifica√ß√µes similares sendo vetorizados m√∫ltiplas vezes
3. **Inconsist√™ncia de Dados**: Possibilidade de informa√ß√µes desatualizadas entre RAG e CRUDs
4. **Performance Sub√≥tima**: M√∫ltiplas consultas HTTP para formar contexto completo

### Casos de Uso Espec√≠ficos:

- **Equipamentos Similares**: Mesmo modelo/fabricante com especifica√ß√µes id√™nticas
- **Sensores Reutilizados**: M√∫ltiplos sensores do mesmo tipo com manual compartilhado
- **Manuais Duplicados**: Mesmo arquivo PDF para diferentes equipamentos
- **FMEA Compartilhada**: An√°lises de falha aplic√°veis a fam√≠lia de equipamentos

## Decis√£o

Implementamos uma **Arquitetura RAG-First com Deduplica√ß√£o Inteligente** onde:

### 1. **Auto-Triggers em Todos os CRUDs**
- Equipment Management Service ‚Üí AUTO-TRIGGER RAG
- Sensor Management Service ‚Üí AUTO-TRIGGER RAG  
- Manual & Documentation Service ‚Üí AUTO-TRIGGER RAG
- Maintenance History Service ‚Üí AUTO-TRIGGER RAG

### 2. **RAG Processing Orchestrator**
- **RAG Coordinator**: Coordena todo processamento autom√°tico
- **Deduplication Engine**: Evita reprocessamento de conte√∫do id√™ntico
- **Content Hasher**: Gera fingerprints para identifica√ß√£o de duplicatas
- **Processing Queue**: Fila priorizada para processamento eficiente

### 3. **Agentes AI - Acesso Exclusivo via RAG**
- ‚úÖ **Anomaly Detection Agent**: Busca contexto APENAS via RAG
- ‚úÖ **Predictive Analysis Agent**: Busca contexto APENAS via RAG
- ‚úÖ **Maintenance Planning Agent**: Busca conhecimento APENAS via RAG
- ‚úÖ **Work Order Agent**: Busca contexto APENAS via RAG
- ‚ö†Ô∏è **Exce√ß√£o √önica**: Work Order Agent registra nova manuten√ß√£o via CRUD

### 4. **Sistema de Deduplica√ß√£o Inteligente**
- **Content Hashing**: MD5/SHA256 para arquivos + structural hash para specs
- **Smart Linking**: Mesmo conte√∫do linkado a m√∫ltiplas entidades
- **Cache Strategy**: Redis para lookup r√°pido de duplicatas
- **Version Tracking**: Controle de vers√µes para updates incrementais

## Alternativas Consideradas

### 1. **Sincroniza√ß√£o Bidirecional RAG ‚Üî CRUD**
- **Pr√≥s**: Mant√©m ambos os sistemas atualizados
- **Contras**: Complexidade alta, possibilidade de inconsist√™ncias
- **Por que rejeitado**: RAG-first √© mais simples e consistente

### 2. **Cache Compartilhado Entre RAG e CRUDs**
- **Pr√≥s**: Evita duplica√ß√£o de dados em mem√≥ria
- **Contras**: N√£o resolve fragmenta√ß√£o de consultas
- **Por que rejeitado**: N√£o elimina depend√™ncias m√∫ltiplas dos agentes

### 3. **Processamento Manual de Deduplica√ß√£o**
- **Pr√≥s**: Controle total sobre quais conte√∫dos s√£o duplicados
- **Contras**: N√£o escal√°vel, propenso a erro humano
- **Por que rejeitado**: Deduplica√ß√£o autom√°tica √© mais eficiente

## Consequ√™ncias

### Positivas ‚úÖ

1. **Performance Otimizada**: Agentes fazem 1 consulta RAG vs m√∫ltiplas consultas CRUD
2. **Consist√™ncia Garantida**: RAG Service como fonte √∫nica de verdade
3. **Processamento Eficiente**: Deduplica√ß√£o evita trabalho redundante
4. **Escalabilidade**: Sistema otimizado para crescimento de dados
5. **Custo Reduzido**: Menos processamento de embeddings duplicados
6. **Manuten√ß√£o Simplificada**: L√≥gica centralizada no RAG Service

### Negativas ‚ùå

1. **Complexidade Inicial**: Implementa√ß√£o do sistema de deduplica√ß√£o
2. **Lat√™ncia de Atualiza√ß√£o**: Delay entre CRUD save e disponibilidade no RAG
3. **Depend√™ncia Cr√≠tica**: RAG Service torna-se ponto √∫nico de falha
4. **Storage Overhead**: Metadados de deduplica√ß√£o no PostgreSQL

### Neutras üü°

1. **Migra√ß√£o de Dados**: Necess√°rio reprocessar base existente com deduplica√ß√£o
2. **Learning Curve**: Equipe precisa entender novo fluxo RAG-first

## Detalhes de Implementa√ß√£o

### Auto-Triggers Webhook Pattern:

```python
# Exemplo: Equipment Service
class EquipmentService:
    async def create_equipment(self, equipment_data: EquipmentCreate):
        # 1. Valida√ß√£o e persist√™ncia
        equipment = await self.repository.create(equipment_data)
        
        # 2. AUTO-TRIGGER para RAG
        await self.rag_webhook.trigger_processing({
            "entity_type": "equipment",
            "entity_id": equipment.id,
            "action": "create",
            "priority": equipment.criticality
        })
        
        return equipment
```

### Deduplication Engine:

```python
class DeduplicationEngine:
    async def check_content_exists(self, content_hash: str) -> Optional[str]:
        # 1. Check Redis cache primeiro
        cached_result = await self.redis.get(f"dedup:{content_hash}")
        if cached_result:
            return cached_result
            
        # 2. Check PostgreSQL para hash existente
        existing = await self.db.query(
            "SELECT vector_id FROM content_hashes WHERE hash = %s", 
            content_hash
        )
        
        if existing:
            # 3. Cache resultado para pr√≥ximas consultas
            await self.redis.setex(
                f"dedup:{content_hash}", 
                3600, 
                existing.vector_id
            )
            return existing.vector_id
            
        return None
```

### RAG Coordinator com Deduplica√ß√£o:

```python
class RAGCoordinator:
    async def process_content(self, request: ProcessingRequest):
        # 1. Gerar hash do conte√∫do
        content_hash = await self.hasher.generate_hash(request)
        
        # 2. Verificar se j√° existe
        existing_vector_id = await self.dedup_engine.check_content_exists(content_hash)
        
        if existing_vector_id:
            # 3. Apenas criar link metadata ‚Üí vector existente
            await self.create_entity_vector_link(
                entity_id=request.entity_id,
                vector_id=existing_vector_id
            )
        else:
            # 4. Processar novo conte√∫do
            await self.processing_queue.enqueue(request, priority=request.priority)
```

### Pinecone Metadata com Deduplica√ß√£o:

```json
{
  "vector_id": "vec_123456",
  "content_hash": "sha256:abc123...",
  "linked_entities": [
    {
      "entity_type": "equipment",
      "entity_id": "eq_001",
      "relationship": "manual"
    },
    {
      "entity_type": "equipment", 
      "entity_id": "eq_002",
      "relationship": "manual"
    }
  ],
  "document_type": "maintenance_manual",
  "manufacturer": "Siemens",
  "model_family": "S7-1500",
  "created_at": "2025-09-08T10:00:00Z",
  "last_updated": "2025-09-08T10:00:00Z"
}
```

## Schema de Banco para Deduplica√ß√£o

```sql
-- Tabela para tracking de hashes de conte√∫do
CREATE TABLE content_hashes (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    content_hash VARCHAR(64) NOT NULL UNIQUE,
    content_type ENUM('manual', 'specification', 'fmea', 'maintenance_case'),
    vector_id VARCHAR(255) NOT NULL,
    file_path VARCHAR(500),
    created_at TIMESTAMP DEFAULT NOW(),
    INDEX idx_content_hash (content_hash),
    INDEX idx_vector_id (vector_id)
);

-- Tabela para linking entities ‚Üí vectors
CREATE TABLE entity_vector_links (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    entity_type ENUM('equipment', 'sensor', 'manual', 'maintenance'),
    entity_id UUID NOT NULL,
    vector_id VARCHAR(255) NOT NULL,
    relationship_type ENUM('specification', 'manual', 'fmea', 'historical_case'),
    created_at TIMESTAMP DEFAULT NOW(),
    INDEX idx_entity (entity_type, entity_id),
    INDEX idx_vector (vector_id)
);

-- Tabela para status de processamento
CREATE TABLE rag_processing_status (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    entity_type ENUM('equipment', 'sensor', 'manual', 'maintenance'),
    entity_id UUID NOT NULL,
    content_hash VARCHAR(64),
    status ENUM('pending', 'processing', 'completed', 'failed'),
    progress INTEGER DEFAULT 0,
    error_message TEXT,
    started_at TIMESTAMP,
    completed_at TIMESTAMP,
    created_at TIMESTAMP DEFAULT NOW()
);
```

## Fluxo de Consulta RAG Otimizado

### Agent Query Example:

```python
# Agent solicita contexto para equipamento espec√≠fico
async def get_equipment_context(self, equipment_id: str) -> str:
    rag_query = f"""
    Buscar informa√ß√µes completas sobre equipamento {equipment_id}:
    - Especifica√ß√µes t√©cnicas
    - Procedimentos de manuten√ß√£o  
    - Hist√≥rico de falhas similares
    - Sensores instalados e caracter√≠sticas
    - An√°lises FMEA relacionadas
    """
    
    # UMA √∫nica consulta RAG retorna contexto completo
    context = await self.rag_service.query(
        query=rag_query,
        filters={
            "entity_id": equipment_id,
            "entity_type": "equipment"
        },
        max_results=50
    )
    
    return context
```

## M√©tricas de Sucesso

### Performance:
- **Query Latency**: < 500ms para consultas RAG complexas
- **Deduplication Rate**: > 40% de conte√∫do deduplicated
- **Processing Efficiency**: > 70% redu√ß√£o em tempo de processamento
- **Storage Savings**: > 60% redu√ß√£o em embeddings duplicados

### Qualidade:
- **Context Accuracy**: > 95% precis√£o em contexto retornado
- **Link Integrity**: < 1% broken links entre entities e vectors
- **Update Latency**: < 2min entre CRUD save e RAG availability

### Operacional:
- **System Availability**: > 99.9% uptime do RAG Service
- **Error Rate**: < 0.1% falha no processamento autom√°tico
- **Cache Hit Rate**: > 80% cache hit para deduplica√ß√£o checks

## Monitoramento e Alertas

### Dashboards:
- **RAG Processing Pipeline**: Status, throughput, error rate
- **Deduplication Metrics**: Savings, cache performance, duplicate detection
- **Agent Query Performance**: Latency, cache hits, context quality
- **Storage Efficiency**: Vector count, deduplication ratio, cost savings

### Alertas Cr√≠ticos:
- RAG Service down/unhealthy
- Processing queue backlog > 1000 items
- Deduplication cache hit rate < 60%
- Agent query latency > 1s (95th percentile)

## Migra√ß√£o e Rollback

### Migra√ß√£o Plan:
1. **Fase 1**: Implementar deduplication engine em parallel
2. **Fase 2**: Reprocessar base existente com deduplica√ß√£o
3. **Fase 3**: Migrar agentes para RAG-only access gradualmente
4. **Fase 4**: Remover acesso direto CRUD dos agentes

### Rollback Strategy:
- Feature flags para reverter agentes para acesso CRUD
- Backup de metadados de deduplica√ß√£o
- Reprocessing capability para regenerar vectors

## Revis√£o Futura

Este ADR deve ser revisado quando:
1. **Q1 2026**: Avalia√ß√£o de performance ap√≥s 6 meses em produ√ß√£o
2. **Q2 2026**: An√°lise de cost savings com deduplica√ß√£o
3. **Sempre**: Quando novos tipos de entidade forem adicionados ao sistema

## Refer√™ncias

- [ADR-001: Pipeline Sequencial Event-Driven](./ADR-001-pipeline-sequencial-trigger-configuravel.md)
- [ADR-002: Gest√£o Completa de Dados Mestre](./ADR-002-gestao-dados-mestre.md)
- [C4 Container Diagram - RAG First](../C4/Nexsora/c2-containers.puml)
- [C4 Component Diagram - Deduplication](../C4/Nexsora/c3-componentes.puml)

---

**Relacionado:**
- ADR-001: Pipeline Sequencial Event-Driven
- ADR-002: Gest√£o Completa de Dados Mestre  
- ADR-004: Vector Database Strategy (Pr√≥ximo)
- ADR-005: Multi-tenant Data Isolation (Pr√≥ximo)